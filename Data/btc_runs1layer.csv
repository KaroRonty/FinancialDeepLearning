"","run_dir","metric_loss","metric_mse","metric_val_loss","metric_val_mse","flag_units1","flag_activation1","flag_recurrent_activation1","flag_recurrent_dropout1","flag_dropout1","flag_batch_size","flag_epochs","flag_loss","flag_optimizer","flag_metrics","epochs","epochs_completed","metrics","model","loss_function","optimizer","learning_rate","script","start","end","completed","output","source_code","context","type"
"1","runs/2021-04-15T21-24-41Z",0.0589,0.0589,0.1212,0.1212,32,"tanh","sigmoid",0,0.5,64,3000,"mse","adam","mse",3000,280,"runs/2021-04-15T21-24-41Z/tfruns.d/metrics.json","Model
Model: ""sequential""
________________________________________________________________________________
Layer (type)                        Output Shape                    Param #     
================================================================================
lstm (LSTM)                         (None, 32)                      4352        
________________________________________________________________________________
dense (Dense)                       (None, 1)                       33          
================================================================================
Total params: 4,385
Trainable params: 4,385
Non-trainable params: 0
________________________________________________________________________________

","mse","<tensorflow.python.keras.optimizer_v2.adam.Adam>",0.00100000004749745,"1_layer_lstm.R",2021-04-15 21:24:41,2021-04-15 21:25:56,TRUE,"
> FLAGS <- flags(flag_integer(""units1"", 4), flag_string(""activation1"", 
+     ""tanh""), flag_string(""recurrent_activation1"", ""sigmoid""), 
+     flag_nu .... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_lstm(units = FLAGS$units1, 
+     activation = FLAGS$activation1, recurrent_activation = FLAGS$recurrent .... [TRUNCATED] 

> model_lstm %>% compile(loss = FLAGS$loss, optimizer = FLAGS$optimizer, 
+     metrics = FLAGS$metrics)

> tic <- Sys.time()

> history_lstm <- model_lstm %>% fit(x = train_x, y = train_y, 
+     batch_size = FLAGS$batch_size, epochs = FLAGS$epochs, verbose = 1, 
+     valida .... [TRUNCATED] ","runs/2021-04-15T21-24-41Z/tfruns.d/source.tar.gz","local","training"
"2","runs/2021-04-15T21-23-06Z",0.0611,0.0611,0.0918,0.0918,16,"tanh","sigmoid",0,0.5,64,3000,"mse","adam","mse",3000,356,"runs/2021-04-15T21-23-06Z/tfruns.d/metrics.json","Model
Model: ""sequential""
________________________________________________________________________________
Layer (type)                        Output Shape                    Param #     
================================================================================
lstm (LSTM)                         (None, 32)                      4352        
________________________________________________________________________________
dense (Dense)                       (None, 1)                       33          
================================================================================
Total params: 4,385
Trainable params: 4,385
Non-trainable params: 0
________________________________________________________________________________

","mse","<tensorflow.python.keras.optimizer_v2.adam.Adam>",0.00100000004749745,"1_layer_lstm.R",2021-04-15 21:23:07,2021-04-15 21:24:41,TRUE,"
> FLAGS <- flags(flag_integer(""units1"", 4), flag_string(""activation1"", 
+     ""tanh""), flag_string(""recurrent_activation1"", ""sigmoid""), 
+     flag_nu .... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_lstm(units = FLAGS$units1, 
+     activation = FLAGS$activation1, recurrent_activation = FLAGS$recurrent .... [TRUNCATED] 

> model_lstm %>% compile(loss = FLAGS$loss, optimizer = FLAGS$optimizer, 
+     metrics = FLAGS$metrics)

> tic <- Sys.time()

> history_lstm <- model_lstm %>% fit(x = train_x, y = train_y, 
+     batch_size = FLAGS$batch_size, epochs = FLAGS$epochs, verbose = 1, 
+     valida .... [TRUNCATED] ","runs/2021-04-15T21-23-06Z/tfruns.d/source.tar.gz","local","training"
"3","runs/2021-04-15T21-21-49Z",0.0604,0.0604,0.0923,0.0923,8,"tanh","sigmoid",0,0.5,64,3000,"mse","adam","mse",3000,295,"runs/2021-04-15T21-21-49Z/tfruns.d/metrics.json","Model
Model: ""sequential""
________________________________________________________________________________
Layer (type)                        Output Shape                    Param #     
================================================================================
lstm (LSTM)                         (None, 32)                      4352        
________________________________________________________________________________
dense (Dense)                       (None, 1)                       33          
================================================================================
Total params: 4,385
Trainable params: 4,385
Non-trainable params: 0
________________________________________________________________________________

","mse","<tensorflow.python.keras.optimizer_v2.adam.Adam>",0.00100000004749745,"1_layer_lstm.R",2021-04-15 21:21:49,2021-04-15 21:23:06,TRUE,"
> FLAGS <- flags(flag_integer(""units1"", 4), flag_string(""activation1"", 
+     ""tanh""), flag_string(""recurrent_activation1"", ""sigmoid""), 
+     flag_nu .... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_lstm(units = FLAGS$units1, 
+     activation = FLAGS$activation1, recurrent_activation = FLAGS$recurrent .... [TRUNCATED] 

> model_lstm %>% compile(loss = FLAGS$loss, optimizer = FLAGS$optimizer, 
+     metrics = FLAGS$metrics)

> tic <- Sys.time()

> history_lstm <- model_lstm %>% fit(x = train_x, y = train_y, 
+     batch_size = FLAGS$batch_size, epochs = FLAGS$epochs, verbose = 1, 
+     valida .... [TRUNCATED] ","runs/2021-04-15T21-21-49Z/tfruns.d/source.tar.gz","local","training"
"4","runs/2021-04-15T21-19-39Z",0.0613,0.0613,0.0877,0.0877,3,"tanh","sigmoid",0,0.5,64,3000,"mse","adam","mse",3000,487,"runs/2021-04-15T21-19-39Z/tfruns.d/metrics.json","Model
Model: ""sequential""
________________________________________________________________________________
Layer (type)                        Output Shape                    Param #     
================================================================================
lstm (LSTM)                         (None, 32)                      4352        
________________________________________________________________________________
dense (Dense)                       (None, 1)                       33          
================================================================================
Total params: 4,385
Trainable params: 4,385
Non-trainable params: 0
________________________________________________________________________________

","mse","<tensorflow.python.keras.optimizer_v2.adam.Adam>",0.00100000004749745,"1_layer_lstm.R",2021-04-15 21:19:40,2021-04-15 21:21:49,TRUE,"
> FLAGS <- flags(flag_integer(""units1"", 4), flag_string(""activation1"", 
+     ""tanh""), flag_string(""recurrent_activation1"", ""sigmoid""), 
+     flag_nu .... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_lstm(units = FLAGS$units1, 
+     activation = FLAGS$activation1, recurrent_activation = FLAGS$recurrent .... [TRUNCATED] 

> model_lstm %>% compile(loss = FLAGS$loss, optimizer = FLAGS$optimizer, 
+     metrics = FLAGS$metrics)

> tic <- Sys.time()

> history_lstm <- model_lstm %>% fit(x = train_x, y = train_y, 
+     batch_size = FLAGS$batch_size, epochs = FLAGS$epochs, verbose = 1, 
+     valida .... [TRUNCATED] ","runs/2021-04-15T21-19-39Z/tfruns.d/source.tar.gz","local","training"
"5","runs/2021-04-15T21-15-26Z",0.0633,0.0633,0.0861,0.0861,32,"tanh","sigmoid",0,0.25,64,3000,"mse","adam","mse",3000,962,"runs/2021-04-15T21-15-26Z/tfruns.d/metrics.json","Model
Model: ""sequential""
________________________________________________________________________________
Layer (type)                        Output Shape                    Param #     
================================================================================
lstm (LSTM)                         (None, 32)                      4352        
________________________________________________________________________________
dense (Dense)                       (None, 1)                       33          
================================================================================
Total params: 4,385
Trainable params: 4,385
Non-trainable params: 0
________________________________________________________________________________

","mse","<tensorflow.python.keras.optimizer_v2.adam.Adam>",0.00100000004749745,"1_layer_lstm.R",2021-04-15 21:15:26,2021-04-15 21:19:39,TRUE,"
> FLAGS <- flags(flag_integer(""units1"", 4), flag_string(""activation1"", 
+     ""tanh""), flag_string(""recurrent_activation1"", ""sigmoid""), 
+     flag_nu .... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_lstm(units = FLAGS$units1, 
+     activation = FLAGS$activation1, recurrent_activation = FLAGS$recurrent .... [TRUNCATED] 

> model_lstm %>% compile(loss = FLAGS$loss, optimizer = FLAGS$optimizer, 
+     metrics = FLAGS$metrics)

> tic <- Sys.time()

> history_lstm <- model_lstm %>% fit(x = train_x, y = train_y, 
+     batch_size = FLAGS$batch_size, epochs = FLAGS$epochs, verbose = 1, 
+     valida .... [TRUNCATED] ","runs/2021-04-15T21-15-26Z/tfruns.d/source.tar.gz","local","training"
"6","runs/2021-04-15T21-13-26Z",0.0634,0.0634,0.0987,0.0987,16,"tanh","sigmoid",0,0.25,64,3000,"mse","adam","mse",3000,453,"runs/2021-04-15T21-13-26Z/tfruns.d/metrics.json","Model
Model: ""sequential""
________________________________________________________________________________
Layer (type)                        Output Shape                    Param #     
================================================================================
lstm (LSTM)                         (None, 32)                      4352        
________________________________________________________________________________
dense (Dense)                       (None, 1)                       33          
================================================================================
Total params: 4,385
Trainable params: 4,385
Non-trainable params: 0
________________________________________________________________________________

","mse","<tensorflow.python.keras.optimizer_v2.adam.Adam>",0.00100000004749745,"1_layer_lstm.R",2021-04-15 21:13:27,2021-04-15 21:15:26,TRUE,"
> FLAGS <- flags(flag_integer(""units1"", 4), flag_string(""activation1"", 
+     ""tanh""), flag_string(""recurrent_activation1"", ""sigmoid""), 
+     flag_nu .... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_lstm(units = FLAGS$units1, 
+     activation = FLAGS$activation1, recurrent_activation = FLAGS$recurrent .... [TRUNCATED] 

> model_lstm %>% compile(loss = FLAGS$loss, optimizer = FLAGS$optimizer, 
+     metrics = FLAGS$metrics)

> tic <- Sys.time()

> history_lstm <- model_lstm %>% fit(x = train_x, y = train_y, 
+     batch_size = FLAGS$batch_size, epochs = FLAGS$epochs, verbose = 1, 
+     valida .... [TRUNCATED] ","runs/2021-04-15T21-13-26Z/tfruns.d/source.tar.gz","local","training"
"7","runs/2021-04-15T21-10-29Z",0.0634,0.0634,0.0977,0.0977,8,"tanh","sigmoid",0,0.25,64,3000,"mse","adam","mse",3000,662,"runs/2021-04-15T21-10-29Z/tfruns.d/metrics.json","Model
Model: ""sequential""
________________________________________________________________________________
Layer (type)                        Output Shape                    Param #     
================================================================================
lstm (LSTM)                         (None, 32)                      4352        
________________________________________________________________________________
dense (Dense)                       (None, 1)                       33          
================================================================================
Total params: 4,385
Trainable params: 4,385
Non-trainable params: 0
________________________________________________________________________________

","mse","<tensorflow.python.keras.optimizer_v2.adam.Adam>",0.00100000004749745,"1_layer_lstm.R",2021-04-15 21:10:30,2021-04-15 21:13:26,TRUE,"
> FLAGS <- flags(flag_integer(""units1"", 4), flag_string(""activation1"", 
+     ""tanh""), flag_string(""recurrent_activation1"", ""sigmoid""), 
+     flag_nu .... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_lstm(units = FLAGS$units1, 
+     activation = FLAGS$activation1, recurrent_activation = FLAGS$recurrent .... [TRUNCATED] 

> model_lstm %>% compile(loss = FLAGS$loss, optimizer = FLAGS$optimizer, 
+     metrics = FLAGS$metrics)

> tic <- Sys.time()

> history_lstm <- model_lstm %>% fit(x = train_x, y = train_y, 
+     batch_size = FLAGS$batch_size, epochs = FLAGS$epochs, verbose = 1, 
+     valida .... [TRUNCATED] ","runs/2021-04-15T21-10-29Z/tfruns.d/source.tar.gz","local","training"
"8","runs/2021-04-15T21-08-37Z",0.0642,0.0642,0.0838,0.0838,3,"tanh","sigmoid",0,0.25,64,3000,"mse","adam","mse",3000,416,"runs/2021-04-15T21-08-37Z/tfruns.d/metrics.json","Model
Model: ""sequential""
________________________________________________________________________________
Layer (type)                        Output Shape                    Param #     
================================================================================
lstm (LSTM)                         (None, 32)                      4352        
________________________________________________________________________________
dense (Dense)                       (None, 1)                       33          
================================================================================
Total params: 4,385
Trainable params: 4,385
Non-trainable params: 0
________________________________________________________________________________

","mse","<tensorflow.python.keras.optimizer_v2.adam.Adam>",0.00100000004749745,"1_layer_lstm.R",2021-04-15 21:08:37,2021-04-15 21:10:29,TRUE,"
> FLAGS <- flags(flag_integer(""units1"", 4), flag_string(""activation1"", 
+     ""tanh""), flag_string(""recurrent_activation1"", ""sigmoid""), 
+     flag_nu .... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_lstm(units = FLAGS$units1, 
+     activation = FLAGS$activation1, recurrent_activation = FLAGS$recurrent .... [TRUNCATED] 

> model_lstm %>% compile(loss = FLAGS$loss, optimizer = FLAGS$optimizer, 
+     metrics = FLAGS$metrics)

> tic <- Sys.time()

> history_lstm <- model_lstm %>% fit(x = train_x, y = train_y, 
+     batch_size = FLAGS$batch_size, epochs = FLAGS$epochs, verbose = 1, 
+     valida .... [TRUNCATED] ","runs/2021-04-15T21-08-37Z/tfruns.d/source.tar.gz","local","training"
"9","runs/2021-04-15T21-06-40Z",0.0652,0.0652,0.0986,0.0986,32,"tanh","sigmoid",0,0,64,3000,"mse","adam","mse",3000,434,"runs/2021-04-15T21-06-40Z/tfruns.d/metrics.json","Model
Model: ""sequential""
________________________________________________________________________________
Layer (type)                        Output Shape                    Param #     
================================================================================
lstm (LSTM)                         (None, 32)                      4352        
________________________________________________________________________________
dense (Dense)                       (None, 1)                       33          
================================================================================
Total params: 4,385
Trainable params: 4,385
Non-trainable params: 0
________________________________________________________________________________

","mse","<tensorflow.python.keras.optimizer_v2.adam.Adam>",0.00100000004749745,"1_layer_lstm.R",2021-04-15 21:06:40,2021-04-15 21:08:37,TRUE,"
> FLAGS <- flags(flag_integer(""units1"", 4), flag_string(""activation1"", 
+     ""tanh""), flag_string(""recurrent_activation1"", ""sigmoid""), 
+     flag_nu .... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_lstm(units = FLAGS$units1, 
+     activation = FLAGS$activation1, recurrent_activation = FLAGS$recurrent .... [TRUNCATED] 

> model_lstm %>% compile(loss = FLAGS$loss, optimizer = FLAGS$optimizer, 
+     metrics = FLAGS$metrics)

> tic <- Sys.time()

> history_lstm <- model_lstm %>% fit(x = train_x, y = train_y, 
+     batch_size = FLAGS$batch_size, epochs = FLAGS$epochs, verbose = 1, 
+     valida .... [TRUNCATED] ","runs/2021-04-15T21-06-40Z/tfruns.d/source.tar.gz","local","training"
"10","runs/2021-04-15T21-03-37Z",0.0661,0.0661,0.0786,0.0786,16,"tanh","sigmoid",0,0,64,3000,"mse","adam","mse",3000,691,"runs/2021-04-15T21-03-37Z/tfruns.d/metrics.json","Model
Model: ""sequential""
________________________________________________________________________________
Layer (type)                        Output Shape                    Param #     
================================================================================
lstm (LSTM)                         (None, 32)                      4352        
________________________________________________________________________________
dense (Dense)                       (None, 1)                       33          
================================================================================
Total params: 4,385
Trainable params: 4,385
Non-trainable params: 0
________________________________________________________________________________

","mse","<tensorflow.python.keras.optimizer_v2.adam.Adam>",0.00100000004749745,"1_layer_lstm.R",2021-04-15 21:03:37,2021-04-15 21:06:40,TRUE,"
> FLAGS <- flags(flag_integer(""units1"", 4), flag_string(""activation1"", 
+     ""tanh""), flag_string(""recurrent_activation1"", ""sigmoid""), 
+     flag_nu .... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_lstm(units = FLAGS$units1, 
+     activation = FLAGS$activation1, recurrent_activation = FLAGS$recurrent .... [TRUNCATED] 

> model_lstm %>% compile(loss = FLAGS$loss, optimizer = FLAGS$optimizer, 
+     metrics = FLAGS$metrics)

> tic <- Sys.time()

> history_lstm <- model_lstm %>% fit(x = train_x, y = train_y, 
+     batch_size = FLAGS$batch_size, epochs = FLAGS$epochs, verbose = 1, 
+     valida .... [TRUNCATED] ","runs/2021-04-15T21-03-37Z/tfruns.d/source.tar.gz","local","training"
"11","runs/2021-04-15T21-02-04Z",0.0674,0.0674,0.0875,0.0875,8,"tanh","sigmoid",0,0,64,3000,"mse","adam","mse",3000,348,"runs/2021-04-15T21-02-04Z/tfruns.d/metrics.json","Model
Model: ""sequential""
________________________________________________________________________________
Layer (type)                        Output Shape                    Param #     
================================================================================
lstm (LSTM)                         (None, 32)                      4352        
________________________________________________________________________________
dense (Dense)                       (None, 1)                       33          
================================================================================
Total params: 4,385
Trainable params: 4,385
Non-trainable params: 0
________________________________________________________________________________

","mse","<tensorflow.python.keras.optimizer_v2.adam.Adam>",0.00100000004749745,"1_layer_lstm.R",2021-04-15 21:02:04,2021-04-15 21:03:37,TRUE,"
> FLAGS <- flags(flag_integer(""units1"", 4), flag_string(""activation1"", 
+     ""tanh""), flag_string(""recurrent_activation1"", ""sigmoid""), 
+     flag_nu .... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_lstm(units = FLAGS$units1, 
+     activation = FLAGS$activation1, recurrent_activation = FLAGS$recurrent .... [TRUNCATED] 

> model_lstm %>% compile(loss = FLAGS$loss, optimizer = FLAGS$optimizer, 
+     metrics = FLAGS$metrics)

> tic <- Sys.time()

> history_lstm <- model_lstm %>% fit(x = train_x, y = train_y, 
+     batch_size = FLAGS$batch_size, epochs = FLAGS$epochs, verbose = 1, 
+     valida .... [TRUNCATED] ","runs/2021-04-15T21-02-04Z/tfruns.d/source.tar.gz","local","training"
"12","runs/2021-04-15T21-00-55Z",0.0689,0.0689,0.1257,0.1257,3,"tanh","sigmoid",0,0,64,3000,"mse","adam","mse",3000,261,"runs/2021-04-15T21-00-55Z/tfruns.d/metrics.json","Model
Model: ""sequential""
________________________________________________________________________________
Layer (type)                        Output Shape                    Param #     
================================================================================
lstm (LSTM)                         (None, 32)                      4352        
________________________________________________________________________________
dense (Dense)                       (None, 1)                       33          
================================================================================
Total params: 4,385
Trainable params: 4,385
Non-trainable params: 0
________________________________________________________________________________

","mse","<tensorflow.python.keras.optimizer_v2.adam.Adam>",0.00100000004749745,"1_layer_lstm.R",2021-04-15 21:00:55,2021-04-15 21:02:04,TRUE,"
> FLAGS <- flags(flag_integer(""units1"", 4), flag_string(""activation1"", 
+     ""tanh""), flag_string(""recurrent_activation1"", ""sigmoid""), 
+     flag_nu .... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_lstm(units = FLAGS$units1, 
+     activation = FLAGS$activation1, recurrent_activation = FLAGS$recurrent .... [TRUNCATED] 

> model_lstm %>% compile(loss = FLAGS$loss, optimizer = FLAGS$optimizer, 
+     metrics = FLAGS$metrics)

> tic <- Sys.time()

> history_lstm <- model_lstm %>% fit(x = train_x, y = train_y, 
+     batch_size = FLAGS$batch_size, epochs = FLAGS$epochs, verbose = 1, 
+     valida .... [TRUNCATED] ","runs/2021-04-15T21-00-55Z/tfruns.d/source.tar.gz","local","training"
